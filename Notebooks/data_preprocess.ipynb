{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Parsing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tickers = pd.read_csv(\"./data/sp500_tickers/sp500_historical.csv\")\n",
    "\n",
    "# ticker = tickers[tickers.date == '2000-01-03'].tickers.iloc[0].split(\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/_7p_zm4x449blqs7bvqvb0rm0000gn/T/ipykernel_1802/3049833917.py:6: DtypeWarning: Columns (11,13,18,21,22,23,24,25,26,27,45,49,50,52,59,60,67,71,72,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  daily_vars = pd.read_csv(\"./data/raw_data/security_daily.csv\", parse_dates = ['datadate'], dtype = {'tic': str})\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     raise Exception\n",
    "#     daily_vars = pd.read_csv(\"./data/preprocess0506/processed/daily_vars.csv\", parse_dates = ['date'], dtype = {'ticker': str})\n",
    "# except:\n",
    "#     daily_vars = pd.read_csv(\"./data/raw_data/security_daily.csv\", parse_dates = ['datadate'], dtype = {'tic': str})\n",
    "#     with open(\"./data/daily_vars.txt\", 'r') as t:\n",
    "#         daily_var = t.read().replace(\"'\", '').split(\"\\n\")\n",
    "#         daily_var = [var for var in daily_var if var not in ['curcddv','curcdd']]\n",
    "#     daily_vars = daily_vars[daily_var]\n",
    "#     col_name_change = {\"tic\" : \"ticker\", 'datadate' : 'date'}\n",
    "#     daily_vars = daily_vars.rename(col_name_change, axis = 1)\n",
    "\n",
    "#     # daily_vars.to_csv(\"./data/preprocess0506/daily_vars.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_vars = pd.read_csv('./data/preprocess0506/final_processed/daily_prices.csv', parse_dates = ['date'], dtype = {'ticker': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend</th>\n",
       "      <th>split</th>\n",
       "      <th>adj_open</th>\n",
       "      <th>adj_high</th>\n",
       "      <th>adj_low</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>adj_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AABA</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>442.90</td>\n",
       "      <td>475.9000</td>\n",
       "      <td>429.5000</td>\n",
       "      <td>475.00</td>\n",
       "      <td>9617400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.421698</td>\n",
       "      <td>32.688385</td>\n",
       "      <td>29.501285</td>\n",
       "      <td>32.626567</td>\n",
       "      <td>38469600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AABA</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>464.50</td>\n",
       "      <td>500.1000</td>\n",
       "      <td>442.0000</td>\n",
       "      <td>443.00</td>\n",
       "      <td>17467200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.905348</td>\n",
       "      <td>34.350623</td>\n",
       "      <td>30.359879</td>\n",
       "      <td>30.428566</td>\n",
       "      <td>69868800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AABA</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>430.50</td>\n",
       "      <td>431.1000</td>\n",
       "      <td>402.0000</td>\n",
       "      <td>420.30</td>\n",
       "      <td>20798700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.569973</td>\n",
       "      <td>29.611185</td>\n",
       "      <td>27.612379</td>\n",
       "      <td>28.869360</td>\n",
       "      <td>83194800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AABA</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>406.30</td>\n",
       "      <td>413.0000</td>\n",
       "      <td>361.0000</td>\n",
       "      <td>368.20</td>\n",
       "      <td>17825300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.907735</td>\n",
       "      <td>28.367941</td>\n",
       "      <td>24.796191</td>\n",
       "      <td>25.290741</td>\n",
       "      <td>71301200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AABA</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>366.80</td>\n",
       "      <td>408.0000</td>\n",
       "      <td>363.0000</td>\n",
       "      <td>407.30</td>\n",
       "      <td>12249900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.194578</td>\n",
       "      <td>28.024504</td>\n",
       "      <td>24.933566</td>\n",
       "      <td>27.976422</td>\n",
       "      <td>48999600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566020</th>\n",
       "      <td>YUM</td>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>99.74</td>\n",
       "      <td>100.4600</td>\n",
       "      <td>99.5300</td>\n",
       "      <td>100.33</td>\n",
       "      <td>656381.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.014714</td>\n",
       "      <td>94.693384</td>\n",
       "      <td>93.816768</td>\n",
       "      <td>94.570846</td>\n",
       "      <td>656381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566021</th>\n",
       "      <td>YUM</td>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>100.61</td>\n",
       "      <td>101.8200</td>\n",
       "      <td>100.3547</td>\n",
       "      <td>101.79</td>\n",
       "      <td>1176882.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.834774</td>\n",
       "      <td>95.975317</td>\n",
       "      <td>94.594128</td>\n",
       "      <td>95.947039</td>\n",
       "      <td>1176882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566022</th>\n",
       "      <td>YUM</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>101.84</td>\n",
       "      <td>102.2000</td>\n",
       "      <td>101.6050</td>\n",
       "      <td>101.90</td>\n",
       "      <td>1130456.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.994169</td>\n",
       "      <td>96.333504</td>\n",
       "      <td>95.772659</td>\n",
       "      <td>96.050725</td>\n",
       "      <td>1130456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566023</th>\n",
       "      <td>YUM</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>101.64</td>\n",
       "      <td>101.6400</td>\n",
       "      <td>100.4500</td>\n",
       "      <td>100.64</td>\n",
       "      <td>1185804.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.805649</td>\n",
       "      <td>95.805649</td>\n",
       "      <td>94.683958</td>\n",
       "      <td>94.863052</td>\n",
       "      <td>1185804.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566024</th>\n",
       "      <td>YUM</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>100.67</td>\n",
       "      <td>101.1652</td>\n",
       "      <td>100.2300</td>\n",
       "      <td>100.73</td>\n",
       "      <td>1271044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.891330</td>\n",
       "      <td>95.358104</td>\n",
       "      <td>94.476586</td>\n",
       "      <td>94.947885</td>\n",
       "      <td>1271044.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1566025 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticker       date    open      high       low   close      volume  \\\n",
       "0         AABA 2000-01-03  442.90  475.9000  429.5000  475.00   9617400.0   \n",
       "1         AABA 2000-01-04  464.50  500.1000  442.0000  443.00  17467200.0   \n",
       "2         AABA 2000-01-05  430.50  431.1000  402.0000  420.30  20798700.0   \n",
       "3         AABA 2000-01-06  406.30  413.0000  361.0000  368.20  17825300.0   \n",
       "4         AABA 2000-01-07  366.80  408.0000  363.0000  407.30  12249900.0   \n",
       "...        ...        ...     ...       ...       ...     ...         ...   \n",
       "1566020    YUM 2019-12-24   99.74  100.4600   99.5300  100.33    656381.0   \n",
       "1566021    YUM 2019-12-26  100.61  101.8200  100.3547  101.79   1176882.0   \n",
       "1566022    YUM 2019-12-27  101.84  102.2000  101.6050  101.90   1130456.0   \n",
       "1566023    YUM 2019-12-30  101.64  101.6400  100.4500  100.64   1185804.0   \n",
       "1566024    YUM 2019-12-31  100.67  101.1652  100.2300  100.73   1271044.0   \n",
       "\n",
       "         dividend  split   adj_open   adj_high    adj_low  adj_close  \\\n",
       "0             0.0    1.0  30.421698  32.688385  29.501285  32.626567   \n",
       "1             0.0    1.0  31.905348  34.350623  30.359879  30.428566   \n",
       "2             0.0    1.0  29.569973  29.611185  27.612379  28.869360   \n",
       "3             0.0    1.0  27.907735  28.367941  24.796191  25.290741   \n",
       "4             0.0    1.0  25.194578  28.024504  24.933566  27.976422   \n",
       "...           ...    ...        ...        ...        ...        ...   \n",
       "1566020       0.0    1.0  94.014714  94.693384  93.816768  94.570846   \n",
       "1566021       0.0    1.0  94.834774  95.975317  94.594128  95.947039   \n",
       "1566022       0.0    1.0  95.994169  96.333504  95.772659  96.050725   \n",
       "1566023       0.0    1.0  95.805649  95.805649  94.683958  94.863052   \n",
       "1566024       0.0    1.0  94.891330  95.358104  94.476586  94.947885   \n",
       "\n",
       "         adj_volume  \n",
       "0        38469600.0  \n",
       "1        69868800.0  \n",
       "2        83194800.0  \n",
       "3        71301200.0  \n",
       "4        48999600.0  \n",
       "...             ...  \n",
       "1566020    656381.0  \n",
       "1566021   1176882.0  \n",
       "1566022   1130456.0  \n",
       "1566023   1185804.0  \n",
       "1566024   1271044.0  \n",
       "\n",
       "[1566025 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    short_interest = pd.read_csv(\"./data/preprocess0506/parsed/short_interest.csv\", parse_dates = ['date'], dtype = {'ticker': str})\n",
    "except:\n",
    "    short_interest = pd.read_csv(\"./data/short_interest_daily.csv\", parse_dates = ['datadate'], dtype = {'tic': str})\n",
    "    with open(\"./data/short_vars.txt\", 'r') as t:\n",
    "        short_var = t.read().replace(\"'\", '').split(\"\\n\")\n",
    "        short_var = [var for var in short_var]\n",
    "    short_interest = short_interest[short_var]\n",
    "    col_name_change = {\"tic\" : \"ticker\", 'datadate' : 'date'}\n",
    "    short_interest = short_interest.rename(col_name_change, axis = 1)\n",
    "\n",
    "    # daily_vars.to_csv(\"./data/preprocess0506/daily_vars.csv\", index = False)\n",
    "    # short_interest.to_csv(\"./data/preprocess0506/short_interest.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise Exception\n",
    "    fin_ratio = pd.read_csv(\"./data/preprocess0506/parsed/fin_ratio_parsed.csv\", parse_dates = ['date', 'qdate'], dtype = {'ticker': str})\n",
    "    fin_firm = pd.read_csv(\"./data/preprocess0506/parsed/fin_firm.csv\", parse_dates = ['date', 'qdate','adate'], dtype = {'ticker': str})\n",
    "    gic_sector = pd.read_csv(\"./data/preprocess0506/parsed/gic_sector.csv\", parse_dates = ['date'], dtype = {'ticker': str})\n",
    "except:\n",
    "    fin_ratio = pd.read_csv(\"./data/raw_data/financial_ratio.csv\", parse_dates = ['public_date', 'qdate'], \n",
    "                            dtype = {'TICKER': str})\n",
    "    fin_firm = pd.read_csv(\"./data/raw_data/fin_firm_raw2.csv\", parse_dates= ['public_date', 'qdate','adate'], \n",
    "                        dtype = {'ticker': str})\n",
    "    gic_sector = pd.read_csv(\"./data/raw_data/GIC_sector_values.csv\", parse_dates= ['public_date'],\n",
    "                            dtype = {'gicdesc': str})\n",
    "\n",
    "    gic_sector['divyield_Median'] = gic_sector.divyield_Median.str.rstrip(\"%\").astype(float)\n",
    "    fin_ratio['divyield'] = fin_ratio.divyield.str.rstrip(\"%\").astype(float)\n",
    "\n",
    "    with open(\"./data/ratio_vars.txt\", 'r') as t:\n",
    "        ratio_vars= t.read().split(\"\\n\")\n",
    "        ratio_vars= [var.replace(\"'\", '') for var in ratio_vars]\n",
    "    fin_ratio = fin_ratio[ratio_vars]\n",
    "\n",
    "    fin_ratio = fin_ratio.rename({\"public_date\" : \"date\", \"TICKER\": \"ticker\"}, axis = 1)\n",
    "    fin_firm = fin_firm.rename({\"public_date\" : \"date\"}, axis = 1)\n",
    "    gic_sector = gic_sector.rename({\"public_date\" : \"date\"}, axis = 1)\n",
    "    fin_ratio.to_csv(\"./data/preprocess0506/parsed/fin_ratio_parsed.csv\", index = False)\n",
    "    fin_firm.to_csv(\"./data/preprocess0506/parsed/fin_firm.csv\", index = False)\n",
    "    gic_sector.to_csv(\"./data/preprocess0506/parsed/gic_sector.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fillna/Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.merge(daily_vars, fin_firm, on = ['ticker', 'date'], how = 'outer')\n",
    "\n",
    "# data['ticker_temp'] = data.ticker\n",
    "# data2 = data.sort_values(by = ['ticker', 'date']).groupby('ticker_temp',as_index=False, ).fillna(method = 'ffill')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firm characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise Exception\n",
    "    firms = pd.read_csv(\"./data/preprocess0506/processed/firms.csv\", parse_dates = ['date'], dtype = {'ticker': str})\n",
    "except:\n",
    "    firms = daily_vars[['ticker', 'date']].copy()\n",
    "    firms = pd.merge(firms, fin_firm, on = ['ticker', 'date'], how = 'outer')\n",
    "    firms['ticker_temp'] = firms.ticker\n",
    "    firms = firms.sort_values(by = ['ticker', 'date']).groupby('ticker_temp').fillna(method = 'ffill')\n",
    "    firms.dropna(subset = ['ticker', 'date'], inplace = True)\n",
    "    date_baseline = daily_vars.ticker.str.cat(daily_vars.date.astype(str), sep = \"_\")\n",
    "    date_check = firms.ticker.str.cat(firms.date.astype(str), sep = \"_\")\n",
    "    firms[date_check.isin(date_baseline)]\n",
    "    firms.to_csv(\"./data/preprocess0506/firms.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GICS Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise Exception\n",
    "    sectors = pd.read_csv(\"./data/preprocess0506/processed/sectors.csv\", parse_dates = ['date'], dtype = {'ticker': str})\n",
    "except:\n",
    "    sectors = firms[['ticker', 'date', 'gicdesc']].copy()\n",
    "    sectors = pd.merge(sectors, gic_sector, on = ['gicdesc', 'date'], how = 'outer')\n",
    "    sectors = sectors.sort_values(by = ['gicdesc', 'date']).groupby('gicdesc').fillna(method = 'ffill')\n",
    "    sectors.dropna(subset = ['ticker', 'date'], inplace = True)\n",
    "    date_baseline = daily_vars.ticker.str.cat(daily_vars.date.astype(str), sep = \"_\")\n",
    "    date_check = sectors.ticker.str.cat(sectors.date.astype(str), sep = \"_\")\n",
    "    sectors[date_check.isin(date_baseline)]\n",
    "    sectors.to_csv(\"./data/preprocess0506/sectors.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Financial Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.merge(data, fin_ratio, on = ['ticker', 'date'], how = 'outer')\n",
    "# data = pd.merge(data, short_interest, on = ['ticker', 'date'], how = 'outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    finratio = pd.read_csv(\"./data/preprocess0506/processed/finratio.csv\", parse_dates = ['date', 'qdate'], dtype = {'ticker': str})\n",
    "except:\n",
    "    finratio = daily_vars[['ticker', 'date']].copy()\n",
    "    finratio = pd.merge(finratio, fin_ratio, on = ['ticker', 'date'], how = 'outer')\n",
    "    finratio['ticker_temp'] = finratio.ticker\n",
    "    finratio = finratio.sort_values(by = ['ticker', 'date']).groupby('ticker_temp').fillna(method = 'ffill')\n",
    "    finratio.dropna(subset = ['ticker', 'date'], inplace = True)\n",
    "    date_baseline = daily_vars.ticker.str.cat(daily_vars.date.astype(str), sep = \"_\")\n",
    "    date_check = finratio.ticker.str.cat(finratio.date.astype(str), sep = \"_\")\n",
    "    finratio[date_check.isin(date_baseline)]\n",
    "    finratio.to_csv(\"./data/preprocess0506/processed/finratio.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise Exception\n",
    "    short_interest_rate = pd.read_csv(\"./data/preprocess0506/processed/short_interest_rate.csv\", parse_dates = ['date'], dtype = {'ticker': str})\n",
    "except:\n",
    "    short_interest_rate = daily_vars[['ticker', 'date']].copy()\n",
    "    short_interest_rate = pd.merge(short_interest_rate, short_interest, on = ['ticker', 'date'], how = 'outer')\n",
    "    short_interest_rate['ticker_temp'] = short_interest_rate.ticker\n",
    "    short_interest_rate = short_interest_rate.sort_values(by = ['ticker', 'date']).groupby('ticker_temp').fillna(method = 'ffill')\n",
    "    short_interest_rate.dropna(subset = ['ticker', 'date'], inplace = True)\n",
    "    date_baseline = daily_vars.ticker.str.cat(daily_vars.date.astype(str), sep = \"_\")\n",
    "    date_check = short_interest_rate.ticker.str.cat(short_interest_rate.date.astype(str), sep = \"_\")\n",
    "    short_interest_rate[date_check.isin(date_baseline)]\n",
    "    short_interest_rate.to_csv(\"./data/preprocess0506/processed/short_interest_rate.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
